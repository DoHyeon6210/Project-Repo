{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc616d3f",
   "metadata": {},
   "source": [
    "# Digits Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2a365a",
   "metadata": {},
   "source": [
    "# 1. 필요한 모듈 import 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0c02ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import sklearn\n",
    "\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0596d529",
   "metadata": {},
   "source": [
    "# 2. 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d868048e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DESCR', 'data', 'feature_names', 'frame', 'images', 'target', 'target_names']\n"
     ]
    }
   ],
   "source": [
    "# 내장 digits 데이터 불러오기\n",
    "digits = load_digits()\n",
    "\n",
    "# dir()는 객체가 어떤 변수와 메서드를 가지고 있는지 나열함\n",
    "print(dir(digits))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df26d54c",
   "metadata": {},
   "source": [
    "# 3. 데이터 이해하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db701574",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터셋에 담긴 정보 종류 확인\n",
    "digits.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dfa0122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n"
     ]
    }
   ],
   "source": [
    "# keys에서 확인한 정보 중 data를 저장\n",
    "digits_data = digits.data\n",
    "print(digits_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7ee195",
   "metadata": {},
   "source": [
    "ㄴ digits_data는 1797개의 레코드와 64개의 이미지 픽셀로 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4c190e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.,  0.,  0., 13., 15., 10.,\n",
       "       15.,  5.,  0.,  0.,  3., 15.,  2.,  0., 11.,  8.,  0.,  0.,  4.,\n",
       "       12.,  0.,  0.,  8.,  8.,  0.,  0.,  5.,  8.,  0.,  0.,  9.,  8.,\n",
       "        0.,  0.,  4., 11.,  0.,  1., 12.,  7.,  0.,  0.,  2., 14.,  5.,\n",
       "       10., 12.,  0.,  0.,  0.,  0.,  6., 13., 10.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 첫 번째 데이터 확인\n",
    "digits_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8f38af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAADyUlEQVR4nO3dUVFjaRRG0T9TYyAWggSwkkgACSABL5FAJBALSCAS7higeZo6vZte6zF5+KiEXbeKB85u27YF9Pzzu38A4GvihChxQpQ4IUqcEPXvd2/udrsf+afc4/E4uvf6+jq2dblcxrZeXl7Gtm6329jWtG3bdl+97skJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEqG/PMfxUk+cR1lrrcDiMbe33+7Gtz8/Psa3T6TS2tdZa5/N5dO8rnpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IypxjuL+/H9uaPI+w1lp3d3djWx8fH2Nbb29vY1uTvx9rOccAfEOcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiMrcStnv92Nb1+t1bGut2fslk6Y/x7+NJydEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROi/spzDJfLZWzrJ5v8zm6329hWhScnRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTojLnGCb/3f79/f3Y1rTJEwmTn+P5fB7bqvDkhChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQtRu27Zfv7nb/frN/9nhcJiaWu/v72Nba6319PQ0tnU8Hse2Jr+zh4eHsa1p27btvnrdkxOixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oSozK2USY+Pj6N7z8/PY1vX63Vs63Q6jW39ZG6lwB9GnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBD17TkG4Pfx5IQocUKUOCFKnBAlTogSJ0T9ByioUst9Wxj9AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 이미지로 확인\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "plt.imshow(digits.data[0].reshape(8, 8), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9dbb6fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, ..., 8, 9, 8])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# digits 데이터의 타겟(레이블)값을 저장\n",
    "digits_label = digits.target\n",
    "\n",
    "print(digits_label.shape)\n",
    "digits_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55d61569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# digits 데이터의 전체 레이블 확인\n",
    "digits.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b8a7ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _digits_dataset:\n",
      "\n",
      "Optical recognition of handwritten digits dataset\n",
      "--------------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 1797\n",
      "    :Number of Attributes: 64\n",
      "    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
      "    :Missing Attribute Values: None\n",
      "    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
      "    :Date: July; 1998\n",
      "\n",
      "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
      "https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
      "\n",
      "The data set contains images of hand-written digits: 10 classes where\n",
      "each class refers to a digit.\n",
      "\n",
      "Preprocessing programs made available by NIST were used to extract\n",
      "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
      "total of 43 people, 30 contributed to the training set and different 13\n",
      "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
      "4x4 and the number of on pixels are counted in each block. This generates\n",
      "an input matrix of 8x8 where each element is an integer in the range\n",
      "0..16. This reduces dimensionality and gives invariance to small\n",
      "distortions.\n",
      "\n",
      "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
      "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
      "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
      "1994.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
      "    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
      "    Graduate Studies in Science and Engineering, Bogazici University.\n",
      "  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
      "  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
      "    Linear dimensionalityreduction using relevance weighted LDA. School of\n",
      "    Electrical and Electronic Engineering Nanyang Technological University.\n",
      "    2005.\n",
      "  - Claudio Gentile. A New Approximate Maximal Margin Classification\n",
      "    Algorithm. NIPS. 2000.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# digits 데이터의 description 확인\n",
    "print(digits.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd37250a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# digits 데이터의 피쳐 이름 확인 - digits 데이터의 피쳐는 픽셀이므로 굳이 확인하지 않는다.\n",
    "# digits.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92d93c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# digits 데이터셋은 filename 이 없다.\n",
    "# digits.filename"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10dbdc1d",
   "metadata": {},
   "source": [
    "# 4. train, test 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03df4a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d0558e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(digits_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b056bad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1437, 64), (1437,), (360, 64), (360,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train, test 셋 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits_data, \n",
    "                                                    digits_label, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=7)\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e398acaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2, 2, 2, ..., 1, 3, 3]),\n",
       " array([6, 0, 5, 9, 2, 9, 0, 4, 1, 0, 1, 8, 2, 5, 2, 8, 1, 8, 9, 1, 0, 2,\n",
       "        0, 4, 5, 3, 3, 0, 0, 4, 1, 4, 4, 4, 6, 1, 4, 0, 6, 6, 0, 9, 3, 6,\n",
       "        6, 2, 0, 1, 9, 6, 2, 8, 9, 9, 0, 2, 0, 8, 4, 6, 8, 5, 8, 7, 8, 7,\n",
       "        7, 4, 1, 4, 5, 5, 4, 6, 2, 0, 1, 3, 7, 5, 8, 2, 4, 4, 2, 5, 1, 9,\n",
       "        3, 7, 6, 3, 3, 5, 6, 2, 1, 0, 1, 9, 4, 1, 1, 3, 1, 6, 9, 0, 3, 7,\n",
       "        6, 9, 3, 8, 0, 8, 3, 8, 8, 6, 3, 7, 3, 9, 0, 3, 0, 9, 8, 1, 2, 2,\n",
       "        3, 6, 9, 4, 0, 5, 4, 2, 9, 1, 0, 2, 5, 0, 2, 2, 7, 4, 6, 9, 8, 2,\n",
       "        6, 0, 4, 4, 8, 5, 0, 2, 4, 6, 8, 2, 3, 7, 2, 9, 0, 3, 5, 9, 1, 6,\n",
       "        8, 7, 5, 3, 0, 4, 2, 1, 3, 3, 6, 0, 2, 8, 4, 1, 4, 7, 5, 7, 6, 6,\n",
       "        8, 1, 0, 6, 8, 7, 1, 1, 9, 8, 5, 5, 3, 6, 8, 1, 2, 0, 7, 5, 3, 0,\n",
       "        8, 2, 0, 4, 0, 9, 4, 8, 4, 7, 9, 7, 3, 6, 2, 5, 1, 5, 9, 2, 9, 9,\n",
       "        8, 2, 1, 6, 7, 1, 7, 5, 7, 8, 9, 5, 7, 4, 3, 7, 8, 8, 2, 8, 9, 5,\n",
       "        3, 2, 8, 0, 4, 2, 1, 0, 8, 4, 1, 7, 1, 4, 7, 7, 1, 8, 3, 8, 4, 3,\n",
       "        5, 9, 4, 4, 8, 1, 8, 7, 2, 3, 1, 1, 1, 0, 2, 8, 0, 7, 4, 0, 1, 0,\n",
       "        2, 3, 7, 9, 8, 5, 8, 2, 2, 6, 5, 0, 8, 9, 8, 9, 0, 0, 9, 7, 4, 1,\n",
       "        2, 6, 7, 3, 7, 4, 0, 2, 1, 7, 2, 5, 7, 2, 3, 5, 7, 1, 4, 1, 3, 3,\n",
       "        8, 8, 1, 0, 1, 9, 3, 0]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label이 잘 분리되었는지 확인\n",
    "y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd00da7",
   "metadata": {},
   "source": [
    "# 5. 다양한 모델로 학습시켜 보기 및 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f09ca3a",
   "metadata": {},
   "source": [
    "#### 5-1. Decision Tree 사용해 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "856a1fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        43\n",
      "           1       0.81      0.81      0.81        42\n",
      "           2       0.79      0.82      0.80        40\n",
      "           3       0.79      0.91      0.85        34\n",
      "           4       0.83      0.95      0.89        37\n",
      "           5       0.90      0.96      0.93        28\n",
      "           6       0.84      0.93      0.88        28\n",
      "           7       0.96      0.82      0.89        33\n",
      "           8       0.88      0.65      0.75        43\n",
      "           9       0.78      0.78      0.78        32\n",
      "\n",
      "    accuracy                           0.86       360\n",
      "   macro avg       0.86      0.86      0.86       360\n",
      "weighted avg       0.86      0.86      0.85       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier \n",
    "\n",
    "# DecisionTreeClassifier 인스턴트 생성\n",
    "decision_tree = DecisionTreeClassifier(random_state=32) \n",
    "\n",
    "# 학습\n",
    "decision_tree.fit(X_train, y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "\n",
    "# 평가 지표 확인\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f4bbb4",
   "metadata": {},
   "source": [
    "#### Decision Tree 모델 평가\n",
    "1. digits 데이터의 픽셀을 보고 숫자를 예측하여 분류하므로 accuracy 를 가지고 모델 성능을 평가하는 것이 적절하다.\n",
    "\n",
    "\n",
    "2. 위 결과 보고서와 같이 Decision Tree 모델의 accuracy 는 0.86 의 예측성능을 나타낸다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ea28f3",
   "metadata": {},
   "source": [
    "#### 5-2. Random Forest 사용해 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e57e034c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        43\n",
      "           1       0.93      1.00      0.97        42\n",
      "           2       1.00      1.00      1.00        40\n",
      "           3       1.00      1.00      1.00        34\n",
      "           4       0.93      1.00      0.96        37\n",
      "           5       0.90      0.96      0.93        28\n",
      "           6       1.00      0.96      0.98        28\n",
      "           7       0.94      0.97      0.96        33\n",
      "           8       1.00      0.84      0.91        43\n",
      "           9       0.94      0.94      0.94        32\n",
      "\n",
      "    accuracy                           0.96       360\n",
      "   macro avg       0.96      0.96      0.96       360\n",
      "weighted avg       0.97      0.96      0.96       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# RandomForestClassifier 인스턴트 생성\n",
    "random_forest = RandomForestClassifier(random_state=32) \n",
    "\n",
    "# 학습\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "# 평가 지표 확인\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6100f791",
   "metadata": {},
   "source": [
    "#### Random Forest 모델 평가\n",
    "1. digits 데이터에 대하여 수행하는 분류 테스크는 일관되기 때문에 Random Forest 모델에서도 accuracy 를 평가 지표로 삼는다.\n",
    "\n",
    "\n",
    "2. 위 결과 보고서와 같이 Random Forest 모델의 accuracy 는 0.96 의 예측성능을 나타낸다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885cfc8b",
   "metadata": {},
   "source": [
    "#### 5-3. SVM 사용해 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "803de558",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        43\n",
      "           1       0.95      1.00      0.98        42\n",
      "           2       1.00      1.00      1.00        40\n",
      "           3       1.00      1.00      1.00        34\n",
      "           4       1.00      1.00      1.00        37\n",
      "           5       0.93      1.00      0.97        28\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      1.00      1.00        33\n",
      "           8       1.00      0.93      0.96        43\n",
      "           9       1.00      0.97      0.98        32\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.99      0.99      0.99       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "# svm.SVC() 인스턴트 생성\n",
    "svm_model = svm.SVC()\n",
    "\n",
    "# 학습\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "# 평가 지표 확인\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae17d9e9",
   "metadata": {},
   "source": [
    "#### SVM 모델 평가\n",
    "1. digits 데이터에 대하여 수행하는 분류 테스크는 일관되기 때문에 SVM 모델에서도 accuracy 를 평가 지표로 삼는다.\n",
    "\n",
    "\n",
    "2. 위 결과 보고서와 같이 SVM 모델의 accuracy 는 0.99 의 예측성능을 나타낸다.\n",
    "\n",
    "\n",
    "3. SVM 의 성능으로 보았을 때 digits 데이터가 선형적으로 잘 구분할 수 있다는 점이 인상에 남는다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b9d293",
   "metadata": {},
   "source": [
    "#### 5-4. Stochastic Gradient Descent Classifier 사용해 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "25ce2102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        43\n",
      "           1       0.84      0.98      0.90        42\n",
      "           2       1.00      1.00      1.00        40\n",
      "           3       0.94      0.91      0.93        34\n",
      "           4       1.00      0.97      0.99        37\n",
      "           5       0.80      1.00      0.89        28\n",
      "           6       0.96      0.93      0.95        28\n",
      "           7       0.97      0.97      0.97        33\n",
      "           8       0.95      0.86      0.90        43\n",
      "           9       1.00      0.78      0.88        32\n",
      "\n",
      "    accuracy                           0.94       360\n",
      "   macro avg       0.95      0.94      0.94       360\n",
      "weighted avg       0.95      0.94      0.94       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# SGDClassifier() 인스턴트 생성\n",
    "sgd_model = SGDClassifier()\n",
    "\n",
    "# 학습\n",
    "sgd_model.fit(X_train, y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred = sgd_model.predict(X_test)\n",
    "\n",
    "# 평가 지표 확인\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8719ab06",
   "metadata": {},
   "source": [
    "#### SGD 모델 평가\n",
    "1. digits 데이터에 대하여 수행하는 분류 테스크는 일관되기 때문에 SGD 모델에서도 accuracy 를 평가 지표로 삼는다.\n",
    "\n",
    "\n",
    "2. 위 결과 보고서와 같이 SGD 모델의 accuracy 는 0.94 의 예측성능을 나타낸다(실행할 때마다 결과가 다르게 나오지만 일부로 random_state 를 설정하지 않음).\n",
    "\n",
    "\n",
    "3. SGD 모델은 랜덤 프로세스로 인해 시행할 때마다 결과의 편차가 크게 나온다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96b7815",
   "metadata": {},
   "source": [
    "#### 5-5. Logistic Regression 사용해 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "85f543fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        43\n",
      "           1       0.95      0.95      0.95        42\n",
      "           2       0.98      1.00      0.99        40\n",
      "           3       0.94      0.97      0.96        34\n",
      "           4       0.97      1.00      0.99        37\n",
      "           5       0.82      0.96      0.89        28\n",
      "           6       1.00      0.96      0.98        28\n",
      "           7       0.97      0.97      0.97        33\n",
      "           8       0.92      0.81      0.86        43\n",
      "           9       0.97      0.91      0.94        32\n",
      "\n",
      "    accuracy                           0.95       360\n",
      "   macro avg       0.95      0.95      0.95       360\n",
      "weighted avg       0.95      0.95      0.95       360\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# LogisticRegression() 인스턴트 생성\n",
    "logistic_model = LogisticRegression()\n",
    "\n",
    "# 학습\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred = logistic_model.predict(X_test)\n",
    "\n",
    "# 평가 지표 확인\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24e8f68",
   "metadata": {},
   "source": [
    "#### Logistic Regression 모델 평가\n",
    "1. digits 데이터에 대하여 수행하는 분류 테스크는 일관되기 때문에 Logistic Regression 모델에서도 accuracy 를 평가 지표로 삼는다.\n",
    "\n",
    "\n",
    "2. 위 결과 보고서와 같이 Logistic Regression 모델의 accuracy 는 0.95 의 예측성능을 나타낸다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440eba13",
   "metadata": {},
   "source": [
    "# Wine Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abc0a15",
   "metadata": {},
   "source": [
    "# 1. 필요한 모듈 import 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "95422924",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a13277",
   "metadata": {},
   "source": [
    "# 2. 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "21f91ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DESCR', 'data', 'feature_names', 'frame', 'target', 'target_names']\n"
     ]
    }
   ],
   "source": [
    "# 내장 wine 데이터 불러오기\n",
    "wine = load_wine()\n",
    "\n",
    "# dir()는 객체가 어떤 변수와 메서드를 가지고 있는지 나열함\n",
    "print(dir(wine))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e31982a",
   "metadata": {},
   "source": [
    "# 3. 데이터 이해하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c819dcf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터셋에 담긴 정보 종류 확인\n",
    "wine.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4b3f1051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178, 13)\n"
     ]
    }
   ],
   "source": [
    "# keys에서 확인한 정보 중 data를 저장\n",
    "wine_data = wine.data\n",
    "print(wine_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238b3c3b",
   "metadata": {},
   "source": [
    "ㄴ wine_data는 178개의 레코드와 13개의 피쳐로 구성\n",
    "\n",
    "- Alcohol\n",
    "- Malic acid\n",
    "- Ash\n",
    "- Alcalinity of ash  \n",
    "- Magnesium\n",
    "- Total phenols\n",
    "- Flavanoids\n",
    "- Nonflavanoid phenols\n",
    "- Proanthocyanins\n",
    "- Color intensity\n",
    "- Hue\n",
    "- OD280/OD315 of diluted wines\n",
    "- Proline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6e990054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>740.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.20</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>835.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>840.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>14.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.74</td>\n",
       "      <td>24.5</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>560.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0      14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1      13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2      13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3      14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4      13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "..       ...         ...   ...                ...        ...            ...   \n",
       "173    13.71        5.65  2.45               20.5       95.0           1.68   \n",
       "174    13.40        3.91  2.48               23.0      102.0           1.80   \n",
       "175    13.27        4.28  2.26               20.0      120.0           1.59   \n",
       "176    13.17        2.59  2.37               20.0      120.0           1.65   \n",
       "177    14.13        4.10  2.74               24.5       96.0           2.05   \n",
       "\n",
       "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0          3.06                  0.28             2.29             5.64  1.04   \n",
       "1          2.76                  0.26             1.28             4.38  1.05   \n",
       "2          3.24                  0.30             2.81             5.68  1.03   \n",
       "3          3.49                  0.24             2.18             7.80  0.86   \n",
       "4          2.69                  0.39             1.82             4.32  1.04   \n",
       "..          ...                   ...              ...              ...   ...   \n",
       "173        0.61                  0.52             1.06             7.70  0.64   \n",
       "174        0.75                  0.43             1.41             7.30  0.70   \n",
       "175        0.69                  0.43             1.35            10.20  0.59   \n",
       "176        0.68                  0.53             1.46             9.30  0.60   \n",
       "177        0.76                  0.56             1.35             9.20  0.61   \n",
       "\n",
       "     od280/od315_of_diluted_wines  proline  \n",
       "0                            3.92   1065.0  \n",
       "1                            3.40   1050.0  \n",
       "2                            3.17   1185.0  \n",
       "3                            3.45   1480.0  \n",
       "4                            2.93    735.0  \n",
       "..                            ...      ...  \n",
       "173                          1.74    740.0  \n",
       "174                          1.56    750.0  \n",
       "175                          1.56    835.0  \n",
       "176                          1.62    840.0  \n",
       "177                          1.60    560.0  \n",
       "\n",
       "[178 rows x 13 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 확인\n",
    "wine_df = pd.DataFrame(data=wine_data, columns=wine.feature_names)\n",
    "wine_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "df2b2ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wine 데이터의 타겟(레이블)값을 저장\n",
    "wine_label = wine.target\n",
    "\n",
    "print(wine_label.shape)\n",
    "wine_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "56f775b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['class_0', 'class_1', 'class_2'], dtype='<U7')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wine 데이터의 전체 레이블 확인\n",
    "wine.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "359b5469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _wine_dataset:\n",
      "\n",
      "Wine recognition dataset\n",
      "------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 178 (50 in each of three classes)\n",
      "    :Number of Attributes: 13 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      " \t\t- Alcohol\n",
      " \t\t- Malic acid\n",
      " \t\t- Ash\n",
      "\t\t- Alcalinity of ash  \n",
      " \t\t- Magnesium\n",
      "\t\t- Total phenols\n",
      " \t\t- Flavanoids\n",
      " \t\t- Nonflavanoid phenols\n",
      " \t\t- Proanthocyanins\n",
      "\t\t- Color intensity\n",
      " \t\t- Hue\n",
      " \t\t- OD280/OD315 of diluted wines\n",
      " \t\t- Proline\n",
      "\n",
      "    - class:\n",
      "            - class_0\n",
      "            - class_1\n",
      "            - class_2\n",
      "\t\t\n",
      "    :Summary Statistics:\n",
      "    \n",
      "    ============================= ==== ===== ======= =====\n",
      "                                   Min   Max   Mean     SD\n",
      "    ============================= ==== ===== ======= =====\n",
      "    Alcohol:                      11.0  14.8    13.0   0.8\n",
      "    Malic Acid:                   0.74  5.80    2.34  1.12\n",
      "    Ash:                          1.36  3.23    2.36  0.27\n",
      "    Alcalinity of Ash:            10.6  30.0    19.5   3.3\n",
      "    Magnesium:                    70.0 162.0    99.7  14.3\n",
      "    Total Phenols:                0.98  3.88    2.29  0.63\n",
      "    Flavanoids:                   0.34  5.08    2.03  1.00\n",
      "    Nonflavanoid Phenols:         0.13  0.66    0.36  0.12\n",
      "    Proanthocyanins:              0.41  3.58    1.59  0.57\n",
      "    Colour Intensity:              1.3  13.0     5.1   2.3\n",
      "    Hue:                          0.48  1.71    0.96  0.23\n",
      "    OD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\n",
      "    Proline:                       278  1680     746   315\n",
      "    ============================= ==== ===== ======= =====\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: class_0 (59), class_1 (71), class_2 (48)\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "This is a copy of UCI ML Wine recognition datasets.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\n",
      "\n",
      "The data is the results of a chemical analysis of wines grown in the same\n",
      "region in Italy by three different cultivators. There are thirteen different\n",
      "measurements taken for different constituents found in the three types of\n",
      "wine.\n",
      "\n",
      "Original Owners: \n",
      "\n",
      "Forina, M. et al, PARVUS - \n",
      "An Extendible Package for Data Exploration, Classification and Correlation. \n",
      "Institute of Pharmaceutical and Food Analysis and Technologies,\n",
      "Via Brigata Salerno, 16147 Genoa, Italy.\n",
      "\n",
      "Citation:\n",
      "\n",
      "Lichman, M. (2013). UCI Machine Learning Repository\n",
      "[https://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\n",
      "School of Information and Computer Science. \n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  (1) S. Aeberhard, D. Coomans and O. de Vel, \n",
      "  Comparison of Classifiers in High Dimensional Settings, \n",
      "  Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of  \n",
      "  Mathematics and Statistics, James Cook University of North Queensland. \n",
      "  (Also submitted to Technometrics). \n",
      "\n",
      "  The data was used with many others for comparing various \n",
      "  classifiers. The classes are separable, though only RDA \n",
      "  has achieved 100% correct classification. \n",
      "  (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data)) \n",
      "  (All results using the leave-one-out technique) \n",
      "\n",
      "  (2) S. Aeberhard, D. Coomans and O. de Vel, \n",
      "  \"THE CLASSIFICATION PERFORMANCE OF RDA\" \n",
      "  Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of \n",
      "  Mathematics and Statistics, James Cook University of North Queensland. \n",
      "  (Also submitted to Journal of Chemometrics).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# wine 데이터의 description 확인\n",
    "print(wine.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bbe8deaf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alcohol',\n",
       " 'malic_acid',\n",
       " 'ash',\n",
       " 'alcalinity_of_ash',\n",
       " 'magnesium',\n",
       " 'total_phenols',\n",
       " 'flavanoids',\n",
       " 'nonflavanoid_phenols',\n",
       " 'proanthocyanins',\n",
       " 'color_intensity',\n",
       " 'hue',\n",
       " 'od280/od315_of_diluted_wines',\n",
       " 'proline']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wine 데이터의 피쳐 이름 확인\n",
    "wine.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3c1f4265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wine 데이터셋은 filename 이 없다.\n",
    "# wine.filename"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e58293f",
   "metadata": {},
   "source": [
    "# 4. train, test 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5f8ee2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cc6af8ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(wine_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0bb63e87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((142, 13), (142,), (36, 13), (36,))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train, test 셋 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(wine_data, \n",
    "                                                    wine_label, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=7)\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "64b97aae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2, 2, 0, 2, 0, 1, 2, 2, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0,\n",
       "        2, 0, 2, 1, 2, 0, 2, 1, 1, 1, 0, 1, 0, 0, 2, 0, 2, 1, 1, 2, 1, 0,\n",
       "        1, 1, 1, 1, 0, 0, 0, 1, 1, 2, 1, 0, 1, 2, 0, 1, 0, 2, 1, 0, 0, 0,\n",
       "        0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 2, 2, 0, 0, 0, 2, 0, 0, 1, 2, 1, 1,\n",
       "        0, 0, 2, 0, 2, 2, 2, 1, 2, 1, 2, 1, 0, 0, 2, 1, 2, 1, 1, 0, 1, 2,\n",
       "        1, 2, 0, 0, 2, 0, 1, 2, 0, 1, 0, 0, 0, 0, 1, 0, 2, 1, 1, 2, 0, 1,\n",
       "        1, 1, 0, 2, 1, 1, 2, 1, 0, 2]),\n",
       " array([2, 0, 2, 2, 1, 2, 1, 0, 1, 2, 0, 1, 2, 1, 1, 1, 1, 2, 0, 0, 1, 1,\n",
       "        1, 1, 0, 2, 1, 2, 2, 2, 1, 0, 2, 1, 1, 1]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label이 잘 분리되었는지 확인\n",
    "y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275243f3",
   "metadata": {},
   "source": [
    "# 5. 다양한 모델로 학습시켜 보기 및 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ae1917",
   "metadata": {},
   "source": [
    "#### 5-1. Decision Tree 사용해 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7ecca57a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.89      1.00      0.94        17\n",
      "           2       1.00      0.83      0.91        12\n",
      "\n",
      "    accuracy                           0.94        36\n",
      "   macro avg       0.96      0.94      0.95        36\n",
      "weighted avg       0.95      0.94      0.94        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier \n",
    "\n",
    "# DecisionTreeClassifier 인스턴트 생성\n",
    "decision_tree = DecisionTreeClassifier(random_state=32) \n",
    "\n",
    "# 학습\n",
    "decision_tree.fit(X_train, y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "\n",
    "# 평가 지표 확인\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e78fdf",
   "metadata": {},
   "source": [
    "#### Decision Tree 모델 평가\n",
    "1. wine 데이터셋은 13가지 피쳐를 학습하여 3종류의 와인으로 분류하는 테스크에 사용하므로, accuracy 를 가지고 분류 성능을 평가하는 것이 적절하다.\n",
    "\n",
    "\n",
    "2. 위 결과 보고서와 같이 Decision Tree 모델의 accuracy 는 0.94 의 예측성능을 나타낸다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e190fb8",
   "metadata": {},
   "source": [
    "#### 5-2. Random Forest 사용해 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "208a42a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       1.00      1.00      1.00        17\n",
      "           2       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# RandomForestClassifier 인스턴트 생성\n",
    "random_forest = RandomForestClassifier(random_state=32) \n",
    "\n",
    "# 학습\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "# 평가 지표 확인\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafeeac9",
   "metadata": {},
   "source": [
    "#### Random Forest 모델 평가\n",
    "1. wine 데이터에 대하여 수행하는 분류 테스크는 일관되기 때문에 Random Forest 모델에서도 accuracy 를 평가 지표로 삼는다.\n",
    "\n",
    "\n",
    "2. 위 결과 보고서와 같이 Random Forest 모델의 accuracy 는 1.00 의 예측성능을 나타낸다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805024e9",
   "metadata": {},
   "source": [
    "#### 5-3. SVM 사용해 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f3970189",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86         7\n",
      "           1       0.58      0.88      0.70        17\n",
      "           2       0.33      0.08      0.13        12\n",
      "\n",
      "    accuracy                           0.61        36\n",
      "   macro avg       0.59      0.61      0.56        36\n",
      "weighted avg       0.55      0.61      0.54        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "# svm.SVC() 인스턴트 생성\n",
    "svm_model = svm.SVC()\n",
    "\n",
    "# 학습\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "# 평가 지표 확인\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a987ea",
   "metadata": {},
   "source": [
    "#### SVM 모델 평가\n",
    "1. wine 데이터에 대하여 수행하는 분류 테스크는 일관되기 때문에 SVM 모델에서도 accuracy 를 평가 지표로 삼는다.\n",
    "\n",
    "\n",
    "2. 위 결과 보고서와 같이 SVM 모델의 accuracy 는 0.61 의 예측성능을 나타낸다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b212912",
   "metadata": {},
   "source": [
    "### 문제해결 회고\n",
    "\n",
    "- 선형 SVM 성능이 트리 기반 모델보다 낮은 것은 데이터가 비선형 패턴을 보이는 것으로 생각할 수 있다. 따라서 SVM 의 커널 인자를 추가하여 비선형 모델링을 시도하기로 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "feb78712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 100, 'gamma': 0.001}\n"
     ]
    }
   ],
   "source": [
    "# 커널을 활용한 SVM 사용을 위해 하이퍼파라미터 튜닝\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 1. Gaussian Radial Basis Function (RBF) kernel 을 사용한 비선형 분류 모델 생성\n",
    "svm_model = svm.SVC(kernel='rbf')\n",
    "\n",
    "# 2. 탐색할 하이퍼파라미터 생성\n",
    "param_grid = {'C': [0.1, 1, 10, 100],  # Regularization parameter\n",
    "              'gamma': [0.001, 0.01, 0.1, 1, 10]}  # Kernel coefficient\n",
    "\n",
    "# 3. GridSearchCV 수행\n",
    "grid_search = GridSearchCV(svm_model, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 4. 최적의 하이퍼파라미터 저장\n",
    "best_hp = grid_search.best_params_\n",
    "print(\"Best parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3064457f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.86      0.80         7\n",
      "           1       0.67      0.82      0.74        17\n",
      "           2       0.71      0.42      0.53        12\n",
      "\n",
      "    accuracy                           0.69        36\n",
      "   macro avg       0.71      0.70      0.69        36\n",
      "weighted avg       0.70      0.69      0.68        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5. 최적의 파라미터로 모델 생성\n",
    "svm_model = svm.SVC(kernel='rbf', C=100, gamma=0.001)\n",
    "\n",
    "# 6. 학습\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# 7. 예측\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "# 8. 평가 지표 확인\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce51b87",
   "metadata": {},
   "source": [
    "#### 결과\n",
    "- rbf 커널과 하이퍼파라미터 튜닝을 적용한 SVM 모델의 경우 이전보다 정확도가 0.61에서 0.69로 향상되었다.\n",
    "\n",
    "\n",
    "- 일반적으로 분류 테스크에서 SVM 이 좋은 성능을 나타내는 것을 경험했지만 wine 데이터셋에 대해서는 성능이 비교적 낮았다.\n",
    "\n",
    "\n",
    "- 비선형 모델링을 해도 성능이 크게 좋아지지 않았는데, 추후 그 이유에 대해 깊게 공부해 보고자 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5655b6ae",
   "metadata": {},
   "source": [
    "#### 5-4. Stochastic Gradient Descent Classifier 사용해 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bdc93c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67         7\n",
      "           1       0.68      0.88      0.77        17\n",
      "           2       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.61        36\n",
      "   macro avg       0.39      0.63      0.48        36\n",
      "weighted avg       0.42      0.61      0.49        36\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# SGDClassifier() 인스턴트 생성\n",
    "sgd_model = SGDClassifier()\n",
    "\n",
    "# 학습\n",
    "sgd_model.fit(X_train, y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred = sgd_model.predict(X_test)\n",
    "\n",
    "# 평가 지표 확인\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd86ac05",
   "metadata": {},
   "source": [
    "#### SGD 모델 평가\n",
    "1. wine 데이터에 대하여 수행하는 분류 테스크는 일관되기 때문에 SGD 모델에서도 accuracy 를 평가 지표로 삼는다.\n",
    "\n",
    "\n",
    "2. 위 결과 보고서와 같이 SGD 모델의 accuracy 는 0.67 의 예측성능을 나타낸다.\n",
    "\n",
    "\n",
    "3. SGD 모델은 랜덤 프로세스로 인해 시행할 때마다 결과의 편차가 크게 나온다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d76061",
   "metadata": {},
   "source": [
    "#### 5-5. Logistic Regression 사용해 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bfd3bd10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.86      0.92         7\n",
      "           1       0.94      1.00      0.97        17\n",
      "           2       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.98      0.95      0.96        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# LogisticRegression() 인스턴트 생성\n",
    "logistic_model = LogisticRegression()\n",
    "\n",
    "# 학습\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred = logistic_model.predict(X_test)\n",
    "\n",
    "# 평가 지표 확인\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5beec0",
   "metadata": {},
   "source": [
    "#### Logistic Regression 모델 평가\n",
    "1. wine 데이터에 대하여 수행하는 분류 테스크는 일관되기 때문에 Logistic Regression 모델에서도 accuracy 를 평가 지표로 삼는다.\n",
    "\n",
    "\n",
    "2. 위 결과 보고서와 같이 Logistic Regression 모델의 accuracy 는 0.97 의 예측성능을 나타낸다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75b7f4b",
   "metadata": {},
   "source": [
    "# Breast Cancer Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09306be3",
   "metadata": {},
   "source": [
    "# 1. 필요한 모듈 import 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dd53579a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85729c89",
   "metadata": {},
   "source": [
    "# 2. 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "89d8baf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DESCR', 'data', 'data_module', 'feature_names', 'filename', 'frame', 'target', 'target_names']\n"
     ]
    }
   ],
   "source": [
    "# 내장 breast_cancer 데이터 불러오기\n",
    "breast_cancer = load_breast_cancer()\n",
    "\n",
    "# dir()는 객체가 어떤 변수와 메서드를 가지고 있는지 나열함\n",
    "print(dir(breast_cancer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c17cf1",
   "metadata": {},
   "source": [
    "# 3. 데이터 이해하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4eaea87a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터셋에 담긴 정보 종류 확인\n",
    "breast_cancer.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8bb4ac29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30)\n"
     ]
    }
   ],
   "source": [
    "# keys에서 확인한 정보 중 data를 저장\n",
    "breast_cancer_data = breast_cancer.data\n",
    "print(breast_cancer_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "34f3b4a4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _breast_cancer_dataset:\n",
      "\n",
      "Breast cancer wisconsin (diagnostic) dataset\n",
      "--------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 569\n",
      "\n",
      "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
      "\n",
      "    :Attribute Information:\n",
      "        - radius (mean of distances from center to points on the perimeter)\n",
      "        - texture (standard deviation of gray-scale values)\n",
      "        - perimeter\n",
      "        - area\n",
      "        - smoothness (local variation in radius lengths)\n",
      "        - compactness (perimeter^2 / area - 1.0)\n",
      "        - concavity (severity of concave portions of the contour)\n",
      "        - concave points (number of concave portions of the contour)\n",
      "        - symmetry\n",
      "        - fractal dimension (\"coastline approximation\" - 1)\n",
      "\n",
      "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
      "        worst/largest values) of these features were computed for each image,\n",
      "        resulting in 30 features.  For instance, field 0 is Mean Radius, field\n",
      "        10 is Radius SE, field 20 is Worst Radius.\n",
      "\n",
      "        - class:\n",
      "                - WDBC-Malignant\n",
      "                - WDBC-Benign\n",
      "\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ===================================== ====== ======\n",
      "                                           Min    Max\n",
      "    ===================================== ====== ======\n",
      "    radius (mean):                        6.981  28.11\n",
      "    texture (mean):                       9.71   39.28\n",
      "    perimeter (mean):                     43.79  188.5\n",
      "    area (mean):                          143.5  2501.0\n",
      "    smoothness (mean):                    0.053  0.163\n",
      "    compactness (mean):                   0.019  0.345\n",
      "    concavity (mean):                     0.0    0.427\n",
      "    concave points (mean):                0.0    0.201\n",
      "    symmetry (mean):                      0.106  0.304\n",
      "    fractal dimension (mean):             0.05   0.097\n",
      "    radius (standard error):              0.112  2.873\n",
      "    texture (standard error):             0.36   4.885\n",
      "    perimeter (standard error):           0.757  21.98\n",
      "    area (standard error):                6.802  542.2\n",
      "    smoothness (standard error):          0.002  0.031\n",
      "    compactness (standard error):         0.002  0.135\n",
      "    concavity (standard error):           0.0    0.396\n",
      "    concave points (standard error):      0.0    0.053\n",
      "    symmetry (standard error):            0.008  0.079\n",
      "    fractal dimension (standard error):   0.001  0.03\n",
      "    radius (worst):                       7.93   36.04\n",
      "    texture (worst):                      12.02  49.54\n",
      "    perimeter (worst):                    50.41  251.2\n",
      "    area (worst):                         185.2  4254.0\n",
      "    smoothness (worst):                   0.071  0.223\n",
      "    compactness (worst):                  0.027  1.058\n",
      "    concavity (worst):                    0.0    1.252\n",
      "    concave points (worst):               0.0    0.291\n",
      "    symmetry (worst):                     0.156  0.664\n",
      "    fractal dimension (worst):            0.055  0.208\n",
      "    ===================================== ====== ======\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
      "\n",
      "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
      "\n",
      "    :Donor: Nick Street\n",
      "\n",
      "    :Date: November, 1995\n",
      "\n",
      "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
      "https://goo.gl/U2Uwz2\n",
      "\n",
      "Features are computed from a digitized image of a fine needle\n",
      "aspirate (FNA) of a breast mass.  They describe\n",
      "characteristics of the cell nuclei present in the image.\n",
      "\n",
      "Separating plane described above was obtained using\n",
      "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
      "Construction Via Linear Programming.\" Proceedings of the 4th\n",
      "Midwest Artificial Intelligence and Cognitive Science Society,\n",
      "pp. 97-101, 1992], a classification method which uses linear\n",
      "programming to construct a decision tree.  Relevant features\n",
      "were selected using an exhaustive search in the space of 1-4\n",
      "features and 1-3 separating planes.\n",
      "\n",
      "The actual linear program used to obtain the separating plane\n",
      "in the 3-dimensional space is that described in:\n",
      "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
      "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
      "Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "This database is also available through the UW CS ftp server:\n",
      "\n",
      "ftp ftp.cs.wisc.edu\n",
      "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
      "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
      "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
      "     San Jose, CA, 1993.\n",
      "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
      "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
      "     July-August 1995.\n",
      "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
      "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
      "     163-171.\n"
     ]
    }
   ],
   "source": [
    "# breast_cancer 데이터의 description 확인\n",
    "print(breast_cancer.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd53095",
   "metadata": {},
   "source": [
    "### ㄴ 해석\n",
    "- breast_cancer_data는 569개의 레코드와 30개의 피쳐로 구성\n",
    "\n",
    "\n",
    "- 각 피쳐는 유방 종양의 디지털 이미지를 통해 계산된 수치이며, 이는 세포 핵의 특성을 설명하는 데이터로 활용할 수 있다. \n",
    " - radius (mean of distances from center to points on the perimeter)\n",
    " - texture (standard deviation of gray-scale values)\n",
    " - perimeter\n",
    " - area\n",
    " - smoothness (local variation in radius lengths)\n",
    " - compactness (perimeter^2 / area - 1.0)\n",
    " - concavity (severity of concave portions of the contour)\n",
    " - concave points (number of concave portions of the contour)\n",
    " - symmetry\n",
    " - fractal dimension (\"coastline approximation\" - 1)\n",
    " \n",
    " \n",
    "- 타겟 컬럼은  Malignant(악성 종양, '0', 212개), Benign(양성 종양, '1', 357개) 로 구성되어 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "42ba8ac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
       "0                   0.07871  ...        25.380          17.33   \n",
       "1                   0.05667  ...        24.990          23.41   \n",
       "2                   0.05999  ...        23.570          25.53   \n",
       "3                   0.09744  ...        14.910          26.50   \n",
       "4                   0.05883  ...        22.540          16.67   \n",
       "..                      ...  ...           ...            ...   \n",
       "564                 0.05623  ...        25.450          26.40   \n",
       "565                 0.05533  ...        23.690          38.25   \n",
       "566                 0.05648  ...        18.980          34.12   \n",
       "567                 0.07016  ...        25.740          39.42   \n",
       "568                 0.05884  ...         9.456          30.37   \n",
       "\n",
       "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
       "0             184.60      2019.0           0.16220            0.66560   \n",
       "1             158.80      1956.0           0.12380            0.18660   \n",
       "2             152.50      1709.0           0.14440            0.42450   \n",
       "3              98.87       567.7           0.20980            0.86630   \n",
       "4             152.20      1575.0           0.13740            0.20500   \n",
       "..               ...         ...               ...                ...   \n",
       "564           166.10      2027.0           0.14100            0.21130   \n",
       "565           155.00      1731.0           0.11660            0.19220   \n",
       "566           126.70      1124.0           0.11390            0.30940   \n",
       "567           184.60      1821.0           0.16500            0.86810   \n",
       "568            59.16       268.6           0.08996            0.06444   \n",
       "\n",
       "     worst concavity  worst concave points  worst symmetry  \\\n",
       "0             0.7119                0.2654          0.4601   \n",
       "1             0.2416                0.1860          0.2750   \n",
       "2             0.4504                0.2430          0.3613   \n",
       "3             0.6869                0.2575          0.6638   \n",
       "4             0.4000                0.1625          0.2364   \n",
       "..               ...                   ...             ...   \n",
       "564           0.4107                0.2216          0.2060   \n",
       "565           0.3215                0.1628          0.2572   \n",
       "566           0.3403                0.1418          0.2218   \n",
       "567           0.9387                0.2650          0.4087   \n",
       "568           0.0000                0.0000          0.2871   \n",
       "\n",
       "     worst fractal dimension  \n",
       "0                    0.11890  \n",
       "1                    0.08902  \n",
       "2                    0.08758  \n",
       "3                    0.17300  \n",
       "4                    0.07678  \n",
       "..                       ...  \n",
       "564                  0.07115  \n",
       "565                  0.06637  \n",
       "566                  0.07820  \n",
       "567                  0.12400  \n",
       "568                  0.07039  \n",
       "\n",
       "[569 rows x 30 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 확인\n",
    "breast_cancer_df = pd.DataFrame(data=breast_cancer_data, columns=breast_cancer.feature_names)\n",
    "breast_cancer_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e9b01842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['malignant', 'benign'], dtype='<U9')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# breast_cancer 데이터의 전체 레이블명 확인\n",
    "breast_cancer.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e7b9fbda",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569,)\n",
      "357\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# breast_cancer 데이터의 타겟(레이블)값을 저장\n",
    "breast_cancer_label = breast_cancer.target\n",
    "\n",
    "print(breast_cancer_label.shape)\n",
    "print(breast_cancer_label.sum())\n",
    "breast_cancer_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e375bc90",
   "metadata": {},
   "source": [
    "#### ㄴ합계를 내면 357 이 나오는데 데이터 description 에 따르면 Benign 클래스가 357 개로 나오므로, \n",
    "#### Benign이 1, Malignant이 0으로 레이블링 되어 있음을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0208c477",
   "metadata": {},
   "source": [
    "## 문제해결 회고.\n",
    "1. breast cancer 데이터셋 활용목표를 악성(Malignant) 종양을 잘 예측하는 테스크로 정한다.\n",
    "2. Malignant 를 1로, Benign(양성 종양)을 0으로 레이블을 변경하여 예측 테스크를 수행하기로 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6ba833aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "212"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# 1. np.where 를 활용하여 0 인 레이블을 1로, 1 인 레이블을 0 으로 수정한다.\n",
    "# 첫번째 인자에 조건, 두번째 인자에 바꿀 값, 세번째 인자에 조건에 맞지 않는 경우 바꿀 값\n",
    "breast_cancer_label = np.where(breast_cancer_label == 0, 1, 0)\n",
    "\n",
    "# 2. 잘 수정되었다면 sum 값이 Malignant 의 개수인 212 만큼 나와야 한다.\n",
    "breast_cancer_label.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f886b34b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "       'smoothness error', 'compactness error', 'concavity error',\n",
       "       'concave points error', 'symmetry error',\n",
       "       'fractal dimension error', 'worst radius', 'worst texture',\n",
       "       'worst perimeter', 'worst area', 'worst smoothness',\n",
       "       'worst compactness', 'worst concavity', 'worst concave points',\n",
       "       'worst symmetry', 'worst fractal dimension'], dtype='<U23')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# breast_cancer 데이터의 피쳐 이름 확인\n",
    "breast_cancer.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6d2c85d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'breast_cancer.csv'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# breast_cancer 데이터셋의 filename\n",
    "breast_cancer.filename"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ea4baf",
   "metadata": {},
   "source": [
    "# 4. train, test 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "94041cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ae44fe23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(breast_cancer_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "77dbdb10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((455, 30), (455,), (114, 30), (114,))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train, test 셋 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(breast_cancer_data, \n",
    "                                                    breast_cancer_label, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=7)\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "41434ac2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "        1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "        0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "        1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "        0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0,\n",
       "        0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "        0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "        0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1,\n",
       "        0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0,\n",
       "        0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "        1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1,\n",
       "        0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "        0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0,\n",
       "        0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0,\n",
       "        1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0,\n",
       "        1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "        1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0,\n",
       "        1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0]),\n",
       " array([0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "        1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1,\n",
       "        0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
       "        0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0]))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label이 잘 분리되었는지 확인\n",
    "y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae3cfca",
   "metadata": {},
   "source": [
    "# 5. 다양한 모델로 학습시켜 보기 및 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38815ead",
   "metadata": {},
   "source": [
    "### 문제해결 회고 : Breast Cancer 데이터셋 모델 평가 지표 설정\n",
    "1. 종양이 악성인지 양성인지 진단하는 테스크를 수행하기 때문에 거짓 음성 비율(FNR)을 줄이는 것이 중요한 모델링 기준이 된다.\n",
    "2. 앞써 악성 종양인 경우를 1로, 양성 종양인 경우 0으로 레이블을 수정했기 때문에 재현율(recall)을 모델 평기 지표로 선정하는 것이 의료진단 테스크를 수행하는데 적절하다.\n",
    "3. 따라서 recall 값을 기준으로 모델을 평가하도록 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b623e4d",
   "metadata": {},
   "source": [
    "#### 5-1. Decision Tree 사용해 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "770e125c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93        74\n",
      "           1       0.92      0.82      0.87        40\n",
      "\n",
      "    accuracy                           0.91       114\n",
      "   macro avg       0.91      0.89      0.90       114\n",
      "weighted avg       0.91      0.91      0.91       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier \n",
    "\n",
    "# DecisionTreeClassifier 인스턴트 생성\n",
    "decision_tree = DecisionTreeClassifier(random_state=32) \n",
    "\n",
    "# 학습\n",
    "decision_tree.fit(X_train, y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "\n",
    "# 평가 지표 확인\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc5a600",
   "metadata": {},
   "source": [
    "#### Decision Tree 모델 평가\n",
    "1. 위 결과 보고서와 같이 Decision Tree 모델의 y = 1 에 대한 recall 성능은 0.82 로 나타난다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b583e823",
   "metadata": {},
   "source": [
    "#### 5-2. Random Forest 사용해 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "96bf96d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99        74\n",
      "           1       1.00      0.95      0.97        40\n",
      "\n",
      "    accuracy                           0.98       114\n",
      "   macro avg       0.99      0.97      0.98       114\n",
      "weighted avg       0.98      0.98      0.98       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# RandomForestClassifier 인스턴트 생성\n",
    "random_forest = RandomForestClassifier(random_state=32) \n",
    "\n",
    "# 학습\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "# 평가 지표 확인\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91594690",
   "metadata": {},
   "source": [
    "#### Random Forest 모델 평가\n",
    "1. 위 결과 보고서와 같이 Random Forest 모델의 y = 1 에 대한 recall 성능은 0.95 로 나타난다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb3378e",
   "metadata": {},
   "source": [
    "#### 5-3. SVM 사용해 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6ea171f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93        74\n",
      "           1       1.00      0.72      0.84        40\n",
      "\n",
      "    accuracy                           0.90       114\n",
      "   macro avg       0.94      0.86      0.89       114\n",
      "weighted avg       0.92      0.90      0.90       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "# svm.SVC() 인스턴트 생성\n",
    "svm_model = svm.SVC()\n",
    "\n",
    "# 학습\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "# 평가 지표 확인\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba702bc8",
   "metadata": {},
   "source": [
    "#### SVM 모델 평가\n",
    "1. 위 결과 보고서와 같이 SVM 모델의 y = 1 에 대한 recall 성능은 0.72 로 나타난다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d38060",
   "metadata": {},
   "source": [
    "#### 비선형 SVM 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "17f07789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 1, 'gamma': 0.001}\n"
     ]
    }
   ],
   "source": [
    "# 커널을 활용한 SVM 사용을 위해 하이퍼파라미터 튜닝\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 1. Gaussian Radial Basis Function (RBF) kernel 을 사용한 비선형 분류 모델 생성\n",
    "svm_model = svm.SVC(kernel='rbf')\n",
    "\n",
    "# 2. 탐색할 하이퍼파라미터 생성\n",
    "param_grid = {'C': [0.1, 1, 10, 100],  # Regularization parameter\n",
    "              'gamma': [0.001, 0.01, 0.1, 1, 10]}  # Kernel coefficient\n",
    "\n",
    "# 3. GridSearchCV 수행\n",
    "grid_search = GridSearchCV(svm_model, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 4. 최적의 하이퍼파라미터 저장\n",
    "best_hp = grid_search.best_params_\n",
    "print(\"Best parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1139b843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.95        74\n",
      "           1       0.90      0.93      0.91        40\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.93      0.94      0.93       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5. 최적의 파라미터로 모델 생성\n",
    "svm_model = svm.SVC(kernel='rbf', C=best_hp['C'], gamma=best_hp['gamma'])\n",
    "\n",
    "# 6. 학습\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# 7. 예측\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "# 8. 평가 지표 확인\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6b17b9",
   "metadata": {},
   "source": [
    "#### 비선형 SVM 모델 평가\n",
    "1. 위 결과 보고서와 같이 비선형 SVM 모델의 y = 1 에 대한 recall 성능은 0.93 으로, 이전 선형 SVM 의 0.72 보다 향상된 성능을 보인다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdbd3b0",
   "metadata": {},
   "source": [
    "#### 5-4. Stochastic Gradient Descent Classifier 사용해 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1e7eb479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91        74\n",
      "           1       1.00      0.62      0.77        40\n",
      "\n",
      "    accuracy                           0.87       114\n",
      "   macro avg       0.92      0.81      0.84       114\n",
      "weighted avg       0.89      0.87      0.86       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# SGDClassifier() 인스턴트 생성\n",
    "sgd_model = SGDClassifier()\n",
    "\n",
    "# 학습\n",
    "sgd_model.fit(X_train, y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred = sgd_model.predict(X_test)\n",
    "\n",
    "# 평가 지표 확인\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9049cb",
   "metadata": {},
   "source": [
    "#### SGD 모델 평가\n",
    "1. 위 결과 보고서와 같이 SGD 모델의 y = 1 에 대한 recall 성능은 0.40 로 가장 낮은 성능을 보였다.\n",
    "2. SGD 모델은 랜덤 프로세스로 인해 시행할 때마다 결과의 편차가 크게 나온다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0602ae",
   "metadata": {},
   "source": [
    "#### 5-5. Logistic Regression 사용해 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fce930e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95        74\n",
      "           1       1.00      0.82      0.90        40\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.96      0.91      0.93       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# LogisticRegression() 인스턴트 생성\n",
    "logistic_model = LogisticRegression()\n",
    "\n",
    "# 학습\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred = logistic_model.predict(X_test)\n",
    "\n",
    "# 평가 지표 확인\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85712791",
   "metadata": {},
   "source": [
    "#### Logistic Regression 모델 평가\n",
    "1. 위 결과 보고서와 같이  Logistic Regression 모델의 y = 1 에 대한 recall 성능은 0.82 로 나타난다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc7b7b4",
   "metadata": {},
   "source": [
    "# 6. 선형 모델을 통해 해석해보기\n",
    "\n",
    ": 로지스틱 회귀 모델을 breast cancer 데이터에 fitting 하여 표본 내 평가 형식으로 독립변수와 종속변수 사이의 상관관계를 분석해본다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50185bec",
   "metadata": {},
   "source": [
    "#### 6-1. 로지스틱 회귀를 통한 독립변수, 종속변수 관계 설명"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1d153775",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.521037</td>\n",
       "      <td>0.022658</td>\n",
       "      <td>0.545989</td>\n",
       "      <td>0.363733</td>\n",
       "      <td>0.593753</td>\n",
       "      <td>0.792037</td>\n",
       "      <td>0.703140</td>\n",
       "      <td>0.731113</td>\n",
       "      <td>0.686364</td>\n",
       "      <td>0.605518</td>\n",
       "      <td>...</td>\n",
       "      <td>0.620776</td>\n",
       "      <td>0.141525</td>\n",
       "      <td>0.668310</td>\n",
       "      <td>0.450698</td>\n",
       "      <td>0.601136</td>\n",
       "      <td>0.619292</td>\n",
       "      <td>0.568610</td>\n",
       "      <td>0.912027</td>\n",
       "      <td>0.598462</td>\n",
       "      <td>0.418864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.643144</td>\n",
       "      <td>0.272574</td>\n",
       "      <td>0.615783</td>\n",
       "      <td>0.501591</td>\n",
       "      <td>0.289880</td>\n",
       "      <td>0.181768</td>\n",
       "      <td>0.203608</td>\n",
       "      <td>0.348757</td>\n",
       "      <td>0.379798</td>\n",
       "      <td>0.141323</td>\n",
       "      <td>...</td>\n",
       "      <td>0.606901</td>\n",
       "      <td>0.303571</td>\n",
       "      <td>0.539818</td>\n",
       "      <td>0.435214</td>\n",
       "      <td>0.347553</td>\n",
       "      <td>0.154563</td>\n",
       "      <td>0.192971</td>\n",
       "      <td>0.639175</td>\n",
       "      <td>0.233590</td>\n",
       "      <td>0.222878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.601496</td>\n",
       "      <td>0.390260</td>\n",
       "      <td>0.595743</td>\n",
       "      <td>0.449417</td>\n",
       "      <td>0.514309</td>\n",
       "      <td>0.431017</td>\n",
       "      <td>0.462512</td>\n",
       "      <td>0.635686</td>\n",
       "      <td>0.509596</td>\n",
       "      <td>0.211247</td>\n",
       "      <td>...</td>\n",
       "      <td>0.556386</td>\n",
       "      <td>0.360075</td>\n",
       "      <td>0.508442</td>\n",
       "      <td>0.374508</td>\n",
       "      <td>0.483590</td>\n",
       "      <td>0.385375</td>\n",
       "      <td>0.359744</td>\n",
       "      <td>0.835052</td>\n",
       "      <td>0.403706</td>\n",
       "      <td>0.213433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.210090</td>\n",
       "      <td>0.360839</td>\n",
       "      <td>0.233501</td>\n",
       "      <td>0.102906</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.811361</td>\n",
       "      <td>0.565604</td>\n",
       "      <td>0.522863</td>\n",
       "      <td>0.776263</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.248310</td>\n",
       "      <td>0.385928</td>\n",
       "      <td>0.241347</td>\n",
       "      <td>0.094008</td>\n",
       "      <td>0.915472</td>\n",
       "      <td>0.814012</td>\n",
       "      <td>0.548642</td>\n",
       "      <td>0.884880</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.773711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.629893</td>\n",
       "      <td>0.156578</td>\n",
       "      <td>0.630986</td>\n",
       "      <td>0.489290</td>\n",
       "      <td>0.430351</td>\n",
       "      <td>0.347893</td>\n",
       "      <td>0.463918</td>\n",
       "      <td>0.518390</td>\n",
       "      <td>0.378283</td>\n",
       "      <td>0.186816</td>\n",
       "      <td>...</td>\n",
       "      <td>0.519744</td>\n",
       "      <td>0.123934</td>\n",
       "      <td>0.506948</td>\n",
       "      <td>0.341575</td>\n",
       "      <td>0.437364</td>\n",
       "      <td>0.172415</td>\n",
       "      <td>0.319489</td>\n",
       "      <td>0.558419</td>\n",
       "      <td>0.157500</td>\n",
       "      <td>0.142595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>0.690000</td>\n",
       "      <td>0.428813</td>\n",
       "      <td>0.678668</td>\n",
       "      <td>0.566490</td>\n",
       "      <td>0.526948</td>\n",
       "      <td>0.296055</td>\n",
       "      <td>0.571462</td>\n",
       "      <td>0.690358</td>\n",
       "      <td>0.336364</td>\n",
       "      <td>0.132056</td>\n",
       "      <td>...</td>\n",
       "      <td>0.623266</td>\n",
       "      <td>0.383262</td>\n",
       "      <td>0.576174</td>\n",
       "      <td>0.452664</td>\n",
       "      <td>0.461137</td>\n",
       "      <td>0.178527</td>\n",
       "      <td>0.328035</td>\n",
       "      <td>0.761512</td>\n",
       "      <td>0.097575</td>\n",
       "      <td>0.105667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>0.622320</td>\n",
       "      <td>0.626987</td>\n",
       "      <td>0.604036</td>\n",
       "      <td>0.474019</td>\n",
       "      <td>0.407782</td>\n",
       "      <td>0.257714</td>\n",
       "      <td>0.337395</td>\n",
       "      <td>0.486630</td>\n",
       "      <td>0.349495</td>\n",
       "      <td>0.113100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.560655</td>\n",
       "      <td>0.699094</td>\n",
       "      <td>0.520892</td>\n",
       "      <td>0.379915</td>\n",
       "      <td>0.300007</td>\n",
       "      <td>0.159997</td>\n",
       "      <td>0.256789</td>\n",
       "      <td>0.559450</td>\n",
       "      <td>0.198502</td>\n",
       "      <td>0.074315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>0.455251</td>\n",
       "      <td>0.621238</td>\n",
       "      <td>0.445788</td>\n",
       "      <td>0.303118</td>\n",
       "      <td>0.288165</td>\n",
       "      <td>0.254340</td>\n",
       "      <td>0.216753</td>\n",
       "      <td>0.263519</td>\n",
       "      <td>0.267677</td>\n",
       "      <td>0.137321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.393099</td>\n",
       "      <td>0.589019</td>\n",
       "      <td>0.379949</td>\n",
       "      <td>0.230731</td>\n",
       "      <td>0.282177</td>\n",
       "      <td>0.273705</td>\n",
       "      <td>0.271805</td>\n",
       "      <td>0.487285</td>\n",
       "      <td>0.128721</td>\n",
       "      <td>0.151909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.663510</td>\n",
       "      <td>0.665538</td>\n",
       "      <td>0.475716</td>\n",
       "      <td>0.588336</td>\n",
       "      <td>0.790197</td>\n",
       "      <td>0.823336</td>\n",
       "      <td>0.755467</td>\n",
       "      <td>0.675253</td>\n",
       "      <td>0.425442</td>\n",
       "      <td>...</td>\n",
       "      <td>0.633582</td>\n",
       "      <td>0.730277</td>\n",
       "      <td>0.668310</td>\n",
       "      <td>0.402035</td>\n",
       "      <td>0.619626</td>\n",
       "      <td>0.815758</td>\n",
       "      <td>0.749760</td>\n",
       "      <td>0.910653</td>\n",
       "      <td>0.497142</td>\n",
       "      <td>0.452315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>0.036869</td>\n",
       "      <td>0.501522</td>\n",
       "      <td>0.028540</td>\n",
       "      <td>0.015907</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.074351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.266162</td>\n",
       "      <td>0.187026</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054287</td>\n",
       "      <td>0.489072</td>\n",
       "      <td>0.043578</td>\n",
       "      <td>0.020497</td>\n",
       "      <td>0.124084</td>\n",
       "      <td>0.036043</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.257441</td>\n",
       "      <td>0.100682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0       0.521037      0.022658        0.545989   0.363733         0.593753   \n",
       "1       0.643144      0.272574        0.615783   0.501591         0.289880   \n",
       "2       0.601496      0.390260        0.595743   0.449417         0.514309   \n",
       "3       0.210090      0.360839        0.233501   0.102906         0.811321   \n",
       "4       0.629893      0.156578        0.630986   0.489290         0.430351   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564     0.690000      0.428813        0.678668   0.566490         0.526948   \n",
       "565     0.622320      0.626987        0.604036   0.474019         0.407782   \n",
       "566     0.455251      0.621238        0.445788   0.303118         0.288165   \n",
       "567     0.644564      0.663510        0.665538   0.475716         0.588336   \n",
       "568     0.036869      0.501522        0.028540   0.015907         0.000000   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0            0.792037        0.703140             0.731113       0.686364   \n",
       "1            0.181768        0.203608             0.348757       0.379798   \n",
       "2            0.431017        0.462512             0.635686       0.509596   \n",
       "3            0.811361        0.565604             0.522863       0.776263   \n",
       "4            0.347893        0.463918             0.518390       0.378283   \n",
       "..                ...             ...                  ...            ...   \n",
       "564          0.296055        0.571462             0.690358       0.336364   \n",
       "565          0.257714        0.337395             0.486630       0.349495   \n",
       "566          0.254340        0.216753             0.263519       0.267677   \n",
       "567          0.790197        0.823336             0.755467       0.675253   \n",
       "568          0.074351        0.000000             0.000000       0.266162   \n",
       "\n",
       "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
       "0                  0.605518  ...      0.620776       0.141525   \n",
       "1                  0.141323  ...      0.606901       0.303571   \n",
       "2                  0.211247  ...      0.556386       0.360075   \n",
       "3                  1.000000  ...      0.248310       0.385928   \n",
       "4                  0.186816  ...      0.519744       0.123934   \n",
       "..                      ...  ...           ...            ...   \n",
       "564                0.132056  ...      0.623266       0.383262   \n",
       "565                0.113100  ...      0.560655       0.699094   \n",
       "566                0.137321  ...      0.393099       0.589019   \n",
       "567                0.425442  ...      0.633582       0.730277   \n",
       "568                0.187026  ...      0.054287       0.489072   \n",
       "\n",
       "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
       "0           0.668310    0.450698          0.601136           0.619292   \n",
       "1           0.539818    0.435214          0.347553           0.154563   \n",
       "2           0.508442    0.374508          0.483590           0.385375   \n",
       "3           0.241347    0.094008          0.915472           0.814012   \n",
       "4           0.506948    0.341575          0.437364           0.172415   \n",
       "..               ...         ...               ...                ...   \n",
       "564         0.576174    0.452664          0.461137           0.178527   \n",
       "565         0.520892    0.379915          0.300007           0.159997   \n",
       "566         0.379949    0.230731          0.282177           0.273705   \n",
       "567         0.668310    0.402035          0.619626           0.815758   \n",
       "568         0.043578    0.020497          0.124084           0.036043   \n",
       "\n",
       "     worst concavity  worst concave points  worst symmetry  \\\n",
       "0           0.568610              0.912027        0.598462   \n",
       "1           0.192971              0.639175        0.233590   \n",
       "2           0.359744              0.835052        0.403706   \n",
       "3           0.548642              0.884880        1.000000   \n",
       "4           0.319489              0.558419        0.157500   \n",
       "..               ...                   ...             ...   \n",
       "564         0.328035              0.761512        0.097575   \n",
       "565         0.256789              0.559450        0.198502   \n",
       "566         0.271805              0.487285        0.128721   \n",
       "567         0.749760              0.910653        0.497142   \n",
       "568         0.000000              0.000000        0.257441   \n",
       "\n",
       "     worst fractal dimension  \n",
       "0                   0.418864  \n",
       "1                   0.222878  \n",
       "2                   0.213433  \n",
       "3                   0.773711  \n",
       "4                   0.142595  \n",
       "..                       ...  \n",
       "564                 0.105667  \n",
       "565                 0.074315  \n",
       "566                 0.151909  \n",
       "567                 0.452315  \n",
       "568                 0.100682  \n",
       "\n",
       "[569 rows x 30 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. 데이터를 0 ~ 1 사이의 값을 가지도록 정규화\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 2. 정규화 과정 함수화\n",
    "def normalize_dataframe(df):\n",
    "    scaler = MinMaxScaler()\n",
    "    normalized_data = scaler.fit_transform(df)\n",
    "    normalized_df = pd.DataFrame(normalized_data, columns=df.columns)\n",
    "    return normalized_df\n",
    "\n",
    "# 3. 표본 내 모델 생성을 위한 데이터 준비 - split 하기 전 전체 데이터를 사용한다.\n",
    "X = pd.DataFrame(breast_cancer_data, columns=breast_cancer.feature_names)\n",
    "\n",
    "# 4. breast cancer dataframe(X) 정규화\n",
    "normalized_X = normalize_dataframe(X)\n",
    "normalized_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1a7365ec",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  569\n",
      "Model:                            GLM   Df Residuals:                      538\n",
      "Model Family:                Binomial   Df Model:                           30\n",
      "Link Function:                  logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                    nan\n",
      "Date:                Tue, 20 Feb 2024   Deviance:                       921.03\n",
      "Time:                        08:42:00   Pearson chi2:                 4.50e+16\n",
      "No. Iterations:                    33   Pseudo R-squ. (CS):                nan\n",
      "Covariance Type:            nonrobust                                         \n",
      "===========================================================================================\n",
      "                              coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------\n",
      "mean radius             -8.514e+16   1.04e+09  -8.17e+07      0.000   -8.51e+16   -8.51e+16\n",
      "mean texture             2.887e+14   6.67e+07   4.33e+06      0.000    2.89e+14    2.89e+14\n",
      "mean perimeter           7.076e+16   1.03e+09   6.86e+07      0.000    7.08e+16    7.08e+16\n",
      "mean area                1.841e+16   3.52e+08   5.23e+07      0.000    1.84e+16    1.84e+16\n",
      "mean smoothness          3.721e+15   6.35e+07   5.86e+07      0.000    3.72e+15    3.72e+15\n",
      "mean compactness        -1.206e+16   1.24e+08  -9.76e+07      0.000   -1.21e+16   -1.21e+16\n",
      "mean concavity           -3.34e+15   1.27e+08  -2.63e+07      0.000   -3.34e+15   -3.34e+15\n",
      "mean concave points      3.399e+15   1.13e+08      3e+07      0.000     3.4e+15     3.4e+15\n",
      "mean symmetry            -1.43e+15   4.18e+07  -3.42e+07      0.000   -1.43e+15   -1.43e+15\n",
      "mean fractal dimension   2.995e+15   7.52e+07   3.98e+07      0.000    2.99e+15    2.99e+15\n",
      "radius error             2.948e+16   2.44e+08   1.21e+08      0.000    2.95e+16    2.95e+16\n",
      "texture error           -1.547e+15   4.74e+07  -3.27e+07      0.000   -1.55e+15   -1.55e+15\n",
      "perimeter error         -2.487e+16   2.48e+08     -1e+08      0.000   -2.49e+16   -2.49e+16\n",
      "area error               1.146e+15   2.13e+08   5.39e+06      0.000    1.15e+15    1.15e+15\n",
      "smoothness error        -1.771e+15   5.54e+07   -3.2e+07      0.000   -1.77e+15   -1.77e+15\n",
      "compactness error        4.817e+15   8.21e+07   5.87e+07      0.000    4.82e+15    4.82e+15\n",
      "concavity error         -1.112e+16   1.46e+08   -7.6e+07      0.000   -1.11e+16   -1.11e+16\n",
      "concave points error     1.063e+16   8.18e+07    1.3e+08      0.000    1.06e+16    1.06e+16\n",
      "symmetry error          -1.872e+15   5.51e+07   -3.4e+07      0.000   -1.87e+15   -1.87e+15\n",
      "fractal dimension error -8.718e+15    9.6e+07  -9.08e+07      0.000   -8.72e+15   -8.72e+15\n",
      "worst radius             2.599e+16   4.63e+08   5.61e+07      0.000     2.6e+16     2.6e+16\n",
      "worst texture            4.582e+15   7.41e+07   6.19e+07      0.000    4.58e+15    4.58e+15\n",
      "worst perimeter          2.031e+16   3.39e+08      6e+07      0.000    2.03e+16    2.03e+16\n",
      "worst area               -4.58e+16    3.7e+08  -1.24e+08      0.000   -4.58e+16   -4.58e+16\n",
      "worst smoothness         8.182e+14   6.17e+07   1.33e+07      0.000    8.18e+14    8.18e+14\n",
      "worst compactness       -3.547e+15   1.12e+08  -3.16e+07      0.000   -3.55e+15   -3.55e+15\n",
      "worst concavity           1.02e+16   9.55e+07   1.07e+08      0.000    1.02e+16    1.02e+16\n",
      "worst concave points    -1.468e+15   7.56e+07  -1.94e+07      0.000   -1.47e+15   -1.47e+15\n",
      "worst symmetry           3.559e+15   7.12e+07      5e+07      0.000    3.56e+15    3.56e+15\n",
      "worst fractal dimension  1.445e+15   1.03e+08    1.4e+07      0.000    1.45e+15    1.45e+15\n",
      "const                   -9.207e+15   2.97e+07   -3.1e+08      0.000   -9.21e+15   -9.21e+15\n",
      "===========================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/statsmodels/genmod/families/links.py:187: RuntimeWarning: overflow encountered in exp\n",
      "  t = np.exp(-z)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/genmod/families/family.py:1014: RuntimeWarning: divide by zero encountered in log\n",
      "  special.gammaln(n - y + 1) + y * np.log(mu / (1 - mu + 1e-20)) +\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/genmod/families/family.py:1014: RuntimeWarning: invalid value encountered in multiply\n",
      "  special.gammaln(n - y + 1) + y * np.log(mu / (1 - mu + 1e-20)) +\n"
     ]
    }
   ],
   "source": [
    "# 1. 표본 내 모델 생성을 위한 데이터 준비\n",
    "y = breast_cancer_label\n",
    "\n",
    "# 2. 라이브러리 호출\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# 3. statsmodels 의 GLM 함수를 통해 로지스틱 회귀 결과 보고서 출력\n",
    "logit_reg_sm = sm.GLM(y, normalized_X.assign(const=1),\n",
    "                      family=sm.families.Binomial())\n",
    "logit_result = logit_reg_sm.fit()\n",
    "print(logit_result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7518289e",
   "metadata": {},
   "source": [
    "#### 해석 및 작은 회고\n",
    "1. 30개 피쳐의 회귀계수에 대한 p값이 모두 0 에 근사함을 확인할 수 있다.\n",
    "2. 독립변수 간의 회귀계수 값의 차이는 매우 크게 나타난다.\n",
    "3. 해당 독립변수가 한 단위 증가할 때 Y=1 일 확률과 아닌 확률의 비율이 평균적으로 exp(회귀계수)로 나타나는데, 회귀계수 값이 매우 극단적이므로 해석에 어려움이 있다.\n",
    "4. 정규화를 해서 다시 시도했지만 회귀계수는 여전히 극단적이게 나왔다.\n",
    "5. 이제 회귀에 대해 더 깊이 있게 공부해야할 시간표가 온 것 같다. 지금까지 배운 것만으로는 데이터를 해석하는데 한계가 있는 것 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8d8e40",
   "metadata": {},
   "source": [
    "#### 6-2. 로지스틱 회귀 편잔차 그래프를 통한 회귀 진단\n",
    "- 참고 : 데이터 과학을 위한 통계학(https://github.com/gedeck/practical-statistics-for-data-scientists/blob/master/python/notebooks/Chapter%205%20-%20Classification.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "096b73a1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.521037</td>\n",
       "      <td>0.022658</td>\n",
       "      <td>0.545989</td>\n",
       "      <td>0.363733</td>\n",
       "      <td>0.593753</td>\n",
       "      <td>0.792037</td>\n",
       "      <td>0.703140</td>\n",
       "      <td>0.731113</td>\n",
       "      <td>0.686364</td>\n",
       "      <td>0.605518</td>\n",
       "      <td>...</td>\n",
       "      <td>0.141525</td>\n",
       "      <td>0.668310</td>\n",
       "      <td>0.450698</td>\n",
       "      <td>0.601136</td>\n",
       "      <td>0.619292</td>\n",
       "      <td>0.568610</td>\n",
       "      <td>0.912027</td>\n",
       "      <td>0.598462</td>\n",
       "      <td>0.418864</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.643144</td>\n",
       "      <td>0.272574</td>\n",
       "      <td>0.615783</td>\n",
       "      <td>0.501591</td>\n",
       "      <td>0.289880</td>\n",
       "      <td>0.181768</td>\n",
       "      <td>0.203608</td>\n",
       "      <td>0.348757</td>\n",
       "      <td>0.379798</td>\n",
       "      <td>0.141323</td>\n",
       "      <td>...</td>\n",
       "      <td>0.303571</td>\n",
       "      <td>0.539818</td>\n",
       "      <td>0.435214</td>\n",
       "      <td>0.347553</td>\n",
       "      <td>0.154563</td>\n",
       "      <td>0.192971</td>\n",
       "      <td>0.639175</td>\n",
       "      <td>0.233590</td>\n",
       "      <td>0.222878</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.601496</td>\n",
       "      <td>0.390260</td>\n",
       "      <td>0.595743</td>\n",
       "      <td>0.449417</td>\n",
       "      <td>0.514309</td>\n",
       "      <td>0.431017</td>\n",
       "      <td>0.462512</td>\n",
       "      <td>0.635686</td>\n",
       "      <td>0.509596</td>\n",
       "      <td>0.211247</td>\n",
       "      <td>...</td>\n",
       "      <td>0.360075</td>\n",
       "      <td>0.508442</td>\n",
       "      <td>0.374508</td>\n",
       "      <td>0.483590</td>\n",
       "      <td>0.385375</td>\n",
       "      <td>0.359744</td>\n",
       "      <td>0.835052</td>\n",
       "      <td>0.403706</td>\n",
       "      <td>0.213433</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.210090</td>\n",
       "      <td>0.360839</td>\n",
       "      <td>0.233501</td>\n",
       "      <td>0.102906</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.811361</td>\n",
       "      <td>0.565604</td>\n",
       "      <td>0.522863</td>\n",
       "      <td>0.776263</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.385928</td>\n",
       "      <td>0.241347</td>\n",
       "      <td>0.094008</td>\n",
       "      <td>0.915472</td>\n",
       "      <td>0.814012</td>\n",
       "      <td>0.548642</td>\n",
       "      <td>0.884880</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.773711</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.629893</td>\n",
       "      <td>0.156578</td>\n",
       "      <td>0.630986</td>\n",
       "      <td>0.489290</td>\n",
       "      <td>0.430351</td>\n",
       "      <td>0.347893</td>\n",
       "      <td>0.463918</td>\n",
       "      <td>0.518390</td>\n",
       "      <td>0.378283</td>\n",
       "      <td>0.186816</td>\n",
       "      <td>...</td>\n",
       "      <td>0.123934</td>\n",
       "      <td>0.506948</td>\n",
       "      <td>0.341575</td>\n",
       "      <td>0.437364</td>\n",
       "      <td>0.172415</td>\n",
       "      <td>0.319489</td>\n",
       "      <td>0.558419</td>\n",
       "      <td>0.157500</td>\n",
       "      <td>0.142595</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>0.690000</td>\n",
       "      <td>0.428813</td>\n",
       "      <td>0.678668</td>\n",
       "      <td>0.566490</td>\n",
       "      <td>0.526948</td>\n",
       "      <td>0.296055</td>\n",
       "      <td>0.571462</td>\n",
       "      <td>0.690358</td>\n",
       "      <td>0.336364</td>\n",
       "      <td>0.132056</td>\n",
       "      <td>...</td>\n",
       "      <td>0.383262</td>\n",
       "      <td>0.576174</td>\n",
       "      <td>0.452664</td>\n",
       "      <td>0.461137</td>\n",
       "      <td>0.178527</td>\n",
       "      <td>0.328035</td>\n",
       "      <td>0.761512</td>\n",
       "      <td>0.097575</td>\n",
       "      <td>0.105667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>0.622320</td>\n",
       "      <td>0.626987</td>\n",
       "      <td>0.604036</td>\n",
       "      <td>0.474019</td>\n",
       "      <td>0.407782</td>\n",
       "      <td>0.257714</td>\n",
       "      <td>0.337395</td>\n",
       "      <td>0.486630</td>\n",
       "      <td>0.349495</td>\n",
       "      <td>0.113100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.699094</td>\n",
       "      <td>0.520892</td>\n",
       "      <td>0.379915</td>\n",
       "      <td>0.300007</td>\n",
       "      <td>0.159997</td>\n",
       "      <td>0.256789</td>\n",
       "      <td>0.559450</td>\n",
       "      <td>0.198502</td>\n",
       "      <td>0.074315</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>0.455251</td>\n",
       "      <td>0.621238</td>\n",
       "      <td>0.445788</td>\n",
       "      <td>0.303118</td>\n",
       "      <td>0.288165</td>\n",
       "      <td>0.254340</td>\n",
       "      <td>0.216753</td>\n",
       "      <td>0.263519</td>\n",
       "      <td>0.267677</td>\n",
       "      <td>0.137321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.589019</td>\n",
       "      <td>0.379949</td>\n",
       "      <td>0.230731</td>\n",
       "      <td>0.282177</td>\n",
       "      <td>0.273705</td>\n",
       "      <td>0.271805</td>\n",
       "      <td>0.487285</td>\n",
       "      <td>0.128721</td>\n",
       "      <td>0.151909</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.663510</td>\n",
       "      <td>0.665538</td>\n",
       "      <td>0.475716</td>\n",
       "      <td>0.588336</td>\n",
       "      <td>0.790197</td>\n",
       "      <td>0.823336</td>\n",
       "      <td>0.755467</td>\n",
       "      <td>0.675253</td>\n",
       "      <td>0.425442</td>\n",
       "      <td>...</td>\n",
       "      <td>0.730277</td>\n",
       "      <td>0.668310</td>\n",
       "      <td>0.402035</td>\n",
       "      <td>0.619626</td>\n",
       "      <td>0.815758</td>\n",
       "      <td>0.749760</td>\n",
       "      <td>0.910653</td>\n",
       "      <td>0.497142</td>\n",
       "      <td>0.452315</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>0.036869</td>\n",
       "      <td>0.501522</td>\n",
       "      <td>0.028540</td>\n",
       "      <td>0.015907</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.074351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.266162</td>\n",
       "      <td>0.187026</td>\n",
       "      <td>...</td>\n",
       "      <td>0.489072</td>\n",
       "      <td>0.043578</td>\n",
       "      <td>0.020497</td>\n",
       "      <td>0.124084</td>\n",
       "      <td>0.036043</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.257441</td>\n",
       "      <td>0.100682</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0       0.521037      0.022658        0.545989   0.363733         0.593753   \n",
       "1       0.643144      0.272574        0.615783   0.501591         0.289880   \n",
       "2       0.601496      0.390260        0.595743   0.449417         0.514309   \n",
       "3       0.210090      0.360839        0.233501   0.102906         0.811321   \n",
       "4       0.629893      0.156578        0.630986   0.489290         0.430351   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564     0.690000      0.428813        0.678668   0.566490         0.526948   \n",
       "565     0.622320      0.626987        0.604036   0.474019         0.407782   \n",
       "566     0.455251      0.621238        0.445788   0.303118         0.288165   \n",
       "567     0.644564      0.663510        0.665538   0.475716         0.588336   \n",
       "568     0.036869      0.501522        0.028540   0.015907         0.000000   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0            0.792037        0.703140             0.731113       0.686364   \n",
       "1            0.181768        0.203608             0.348757       0.379798   \n",
       "2            0.431017        0.462512             0.635686       0.509596   \n",
       "3            0.811361        0.565604             0.522863       0.776263   \n",
       "4            0.347893        0.463918             0.518390       0.378283   \n",
       "..                ...             ...                  ...            ...   \n",
       "564          0.296055        0.571462             0.690358       0.336364   \n",
       "565          0.257714        0.337395             0.486630       0.349495   \n",
       "566          0.254340        0.216753             0.263519       0.267677   \n",
       "567          0.790197        0.823336             0.755467       0.675253   \n",
       "568          0.074351        0.000000             0.000000       0.266162   \n",
       "\n",
       "     mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                  0.605518  ...       0.141525         0.668310    0.450698   \n",
       "1                  0.141323  ...       0.303571         0.539818    0.435214   \n",
       "2                  0.211247  ...       0.360075         0.508442    0.374508   \n",
       "3                  1.000000  ...       0.385928         0.241347    0.094008   \n",
       "4                  0.186816  ...       0.123934         0.506948    0.341575   \n",
       "..                      ...  ...            ...              ...         ...   \n",
       "564                0.132056  ...       0.383262         0.576174    0.452664   \n",
       "565                0.113100  ...       0.699094         0.520892    0.379915   \n",
       "566                0.137321  ...       0.589019         0.379949    0.230731   \n",
       "567                0.425442  ...       0.730277         0.668310    0.402035   \n",
       "568                0.187026  ...       0.489072         0.043578    0.020497   \n",
       "\n",
       "     worst smoothness  worst compactness  worst concavity  \\\n",
       "0            0.601136           0.619292         0.568610   \n",
       "1            0.347553           0.154563         0.192971   \n",
       "2            0.483590           0.385375         0.359744   \n",
       "3            0.915472           0.814012         0.548642   \n",
       "4            0.437364           0.172415         0.319489   \n",
       "..                ...                ...              ...   \n",
       "564          0.461137           0.178527         0.328035   \n",
       "565          0.300007           0.159997         0.256789   \n",
       "566          0.282177           0.273705         0.271805   \n",
       "567          0.619626           0.815758         0.749760   \n",
       "568          0.124084           0.036043         0.000000   \n",
       "\n",
       "     worst concave points  worst symmetry  worst fractal dimension  outcome  \n",
       "0                0.912027        0.598462                 0.418864        1  \n",
       "1                0.639175        0.233590                 0.222878        1  \n",
       "2                0.835052        0.403706                 0.213433        1  \n",
       "3                0.884880        1.000000                 0.773711        1  \n",
       "4                0.558419        0.157500                 0.142595        1  \n",
       "..                    ...             ...                      ...      ...  \n",
       "564              0.761512        0.097575                 0.105667        1  \n",
       "565              0.559450        0.198502                 0.074315        1  \n",
       "566              0.487285        0.128721                 0.151909        1  \n",
       "567              0.910653        0.497142                 0.452315        1  \n",
       "568              0.000000        0.257441                 0.100682        0  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. 편잔차를 그리는 함수에 적용하기 위해 데이터를 전처리한다.\n",
    "normalized_X['outcome'] = y\n",
    "normalized_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "45a41b31",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/statsmodels/genmod/families/links.py:187: RuntimeWarning: overflow encountered in exp\n",
      "  t = np.exp(-z)\n",
      "/opt/conda/lib/python3.9/site-packages/pandas/core/arraylike.py:364: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from statsmodels.genmod.generalized_linear_model import GLMResults\n",
    "\n",
    "# 2. 편잔차 플롯 함수 정의\n",
    "def partialResidualPlot(model, df, outcome, feature, fig, ax):\n",
    "    y_actual = df[outcome]\n",
    "    y_pred = model.predict(df)\n",
    "    org_params = model.params.copy()\n",
    "    zero_params = model.params.copy()\n",
    "    \n",
    "    # set model parametes of other features to 0\n",
    "    for i, name in enumerate(zero_params.index):\n",
    "        if feature in name:\n",
    "            continue\n",
    "        zero_params[i] = 0.0\n",
    "    model.initialize(model.model, zero_params)\n",
    "    feature_prediction = model.predict(df)\n",
    "    ypartial = -np.log(1/feature_prediction - 1)\n",
    "    ypartial = ypartial - np.mean(ypartial)\n",
    "    model.initialize(model.model, org_params)\n",
    "    results = pd.DataFrame({\n",
    "        'feature': df[feature],\n",
    "        'residual': -2 * (y_actual - y_pred),\n",
    "        'ypartial': ypartial/ 2,\n",
    "    })\n",
    "    results = results.sort_values(by=['feature'])\n",
    "\n",
    "    ax.scatter(results.feature, results.residual, marker=\".\", s=72./fig.dpi)\n",
    "    ax.plot(results.feature, results.ypartial, color='black')\n",
    "    ax.set_xlabel(feature)\n",
    "    ax.set_ylabel(f'Residual + {feature} contribution')\n",
    "    return ax\n",
    "\n",
    "# 3. 시각화 - 독립변수 하나를 인자로 받는다. 회귀계수가 가장 큰 mean perimeter 변수를 사용함.\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "partialResidualPlot(logit_result, normalized_X, 'outcome', 'mean perimeter', fig, ax)\n",
    "# ax.set_xlim(0, 25)\n",
    "# ax.set_ylim(-2.5, 2.5)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17a214e",
   "metadata": {},
   "source": [
    "## 최종 회고\n",
    "1. 마지막 부분에서 로지스틱 회귀에 대한 편잔차 플롯을 시각화해서 회귀 진단을 시도해 보았다. 그러나 그래프가 생각한 것처럼 나오지 않아 데이터를 정규화해서 다시 시도했는데, y축이 +2 ~ -2 사이의 정상적인 범위가 나오긴 했다. 책과는 다른 그림이 나와 어떻게 해석해야할지 감이 잡히지 않는다. 회귀에 대해 더 깊게 공부해야 할 필요성을 느낀다.\n",
    "\n",
    "\n",
    "2. 하이퍼파라미터 튜닝을 거친 커널 SVM 을 데이터셋에 적용해 보았다. 와인 데이터셋에서는 약 7% 정도 성능 향상이 있었지만, 유방암 데이터셋에서는 약 20% 의 성능 향상이 있었다. 와인 데이터셋의 경우 다른 비선형 모델의 성능이 좋았는데, 왜 커널 SVM 성능은 높지 않았는지 추후 공부하고 싶은 탐구심이 생겼다.\n",
    "\n",
    "\n",
    "3. SDG 모델은 그 이름답게 실행할 때마다 결과가 다양하게 나왔다. 일부로 랜덤스태이트을 설정하지는 않았다.\n",
    "\n",
    "\n",
    "4. 내장 데이터를 사용해서 그런지 데이터에 대한 흥미가 크게 일어나지는 않았다. 그러나 프로젝트의 전체적인 과정을 이해하고 연습하는데 많은 도움이 되었다.\n",
    "\n",
    "\n",
    "5. 토이 데이터를 통해서는 끌어낼 수 있는 인사이트가 떠오르지는 않았다. 다만 추가적인 여러 시도와 해석을 하면서 나만의 인사이트를 확보해가는 시간이 되었다(회귀 분석을 통한 변수간의 관계 설명과 잔차플롯을 통한 회귀 진단과 해석을 시도함)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
